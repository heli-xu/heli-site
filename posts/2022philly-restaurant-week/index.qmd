---
title: "Philly Center City Distric Restaurant Week 2022"
author: "Heli Xu"
date: "2022-10-04"
categories: [news, code, analysis]
image: "image.jpg"
format:
  html:
    code-link: true
    toc: true
    toc-location: left
execute: 
  cache: true
---

# Introduction

This is based on an R-ladies Philly (link) workshop on webscraping, geocoding, and interactive map-making, presented by Silvia Canel√≥n. I found it really interesting and helpful, and Silvia made it easy to follow, even though I had zero experience making maps prior to that. I'm replicating steps from Silvia's tutorial using another set of data from Center City District. The goal is to visualize all the restaurants participating in the 2022 CCD Restaurant Week in an interactive map.

```{r}
#| warning: false
library(tidyverse)
library(here)
library(knitr)
library(robotstxt)
library(rvest)
library(tidygeocoder)
library(leaflet)
library(leaflet.extras)
```

# Scraping the data

We will scrape the data from the list view: <https://centercityphila.org/explore-center-city/ccd-restaurant-week/list-view>

## checking site permissions

To check if an pages are not allowed to be scraped, we are using robotstxt package.

```{r}
get_robotstxt("https://centercityphila.org/explore-center-city/ccd-restaurant-week/list-view")
```

(sometimes it says something about not resolving host-the website-but it goes away but itself after a few tries.)

## Harvesting data from the first page

We are using In the list view from the website, all restaurants are split into four pages, so we'd need a function to scrape each page. Before that, we'll check the function with the first page.

```{r}

# define the page (click on page 1 at the bottom)
url1 <- "https://centercityphila.org/explore-center-city/ccd-restaurant-week/list-view?page=1"

# read the page html
html1 <- read_html(url1)

# extract table info (inspect elements)
table1 <- html1 %>% 
  html_node("table") %>% 
  html_table()
table1 %>% head() %>% kable()  # if piped all the way down it doesn't print

# extract hyperlinks to specific restaurant menus (popup window)
# can right click-copy link address to see what it's supposed to look at 
links <- html1 %>% 
  html_elements(".o-table__tag.ccd-text-link") %>% 
  html_attr("href") %>% # a vector 
  as_tibble() 
links %>% head() %>% kable()

# add links to the table 
table1_link <- bind_cols(table1, links) %>% 
  mutate(Menu = paste0(url1, value)) %>% 
  select(-c('Menu & Reservations', value)) 
table1_link %>% head() %>% kable()
```

## Create a function to harvest data from remaining pages

```{r}
getTables <- function(pageNumber) {
  # wait 2 seconds between each page 
  Sys.sleep(2)
  
  url <- paste0("https://centercityphila.org/explore-center-city/ccd-restaurant-week/list-view?page=", pageNumber)
  
  # read the page html
  html <- read_html(url)
  
  # extract table info
  table <- html %>% 
    html_node("table") %>% 
    html_table()
  
  # extract hyperlinks to specific restaurant menus (popup window)
  links <- html %>%
    html_elements(".o-table__tag.ccd-text-link") %>%
    html_attr("href") %>% # a vector
    as_tibble() 
  
  # add links to the table
  table_link <- bind_cols(table, links) %>%
    mutate(Menu = paste0(url, value)) %>%
    select(-c('Menu & Reservations', value))
}
```

After creating the function, we can use purrr::map_df() to repeat the data harvesting for the rest of pages (2-4). Then we can combine all the data frames together and save the final data frame as and .rds. object, so that we don't have to keep scraping every time.

```{r}
#| eval: false

# get remaining table
table2_4 <- map_df(2:4, getTables)

# combine all tables
table_all <- bind_rows(table1_link, table2_4)
table_all %>% head() %>% kable()

#tryout with or without kable()
table_all %>% head()

# save full table to file
write_rds(table_all, file = here("data", "restaurant_list_links.rds"))
```

Side note: saveRDS vs write_rds: the only major difference between the two is that `write_rds()` does not compress the file by default.

(I only added cache: true at his point, to avoid repeated scraping, I'll load the . rds file here for downstream visualization.)

```{r}
#| echo: false
table_all <- readRDS("data/restaurant_list_links.rds")
table_all %>% head() %>% kable()

```

# Geocoding addresses

This step is to convert restaurant addresses to geographical coordinates (longitude and latitude) for mapping. Now we're using tidygeocoder package, with ArcGIS geocoding service.

```{r}
# geocode adresses-adding log/latt to the table
table_geo <- table_all %>% 
  geocode(address = Address,
          method = 'arcgis',
          long = Longtitude,
          lat = Latitude)
table_geo %>% head() %>% kable()
```

It's time to save this new dataframe as another .rds object so we don't have to spend that 39.5s to geocode the same data again next time we need to map the data.

```{r}
write_rds(table_geo, "data/restaurant_list_geocoded.rds")

```

# Building the map

Here comes leaflet!!

## Plotting the restaurants

To customize labels, we could add a \[Google Font\]\[https://fonts.google.com/\] with a css chunk to import the font faces/weights.

```{css}
@import url('https://fonts.googleapis.com/css2?family=Fira+Sans:wght@500&display=swap');

```

```{r}
circles <- 
  leaflet(data = table_geo,
        options = tileOptions(minZoom = 15,
                              maxZoom = 19)) %>% 
  #add map markers
  addCircles(lat = table_geo$Latitude,
             lng = table_geo$Longtitude,
             popup = table_geo$Address,
             label = table_geo$Name,
             #customize labels
             labelOptions = labelOptions(
               style = list(
                 "font-family" = "Fira Sans, sans-serif",
                 "font-size" = "1.2em"
               )
             ))

circles
```

## Adding map background

```{r}
# add map tiles in the background
circles_map <- circles %>% 
  addProviderTiles(providers$CartoDB.Voyager)
circles_map
```

## Setting the map view

```{r}
# roughly set the center of all restaurants
circles_map_view <- circles_map %>% 
  setView(lng  = mean(table_geo$Longtitude),
          lat = mean(table_geo$Latitude),
          zoom = 16)
circles_map_view
```

## Adding full screen control

```{r}
circles_map_view %>% 
  addFullscreenControl()
```
